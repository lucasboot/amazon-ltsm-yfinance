# Artifacts - Modelo e Scaler

Esta pasta deve conter os artefatos do modelo LSTM treinado.

## üìÅ Arquivos Necess√°rios

### 1. `amzn_lstm_model.keras`
- **Tipo:** Modelo TensorFlow/Keras
- **Formato:** `.keras` (formato recomendado do Keras 3.x)
- **Descri√ß√£o:** Modelo LSTM treinado para predi√ß√£o de pre√ßos

**Como gerar:**
```python
# Ap√≥s treinar seu modelo
model.save('artifacts/amzn_lstm_model.keras')
```

---

### 2. `scaler.save`
- **Tipo:** Scaler scikit-learn
- **Formato:** Arquivo joblib
- **Descri√ß√£o:** Scaler usado para normalizar/desnormalizar dados

**Como gerar:**
```python
import joblib
from sklearn.preprocessing import MinMaxScaler

# Ap√≥s treinar o scaler
scaler = MinMaxScaler()
scaler.fit(X_train)  # X_train com suas 5 features (OHLCV)

# Salvar
joblib.dump(scaler, 'artifacts/scaler.save')
```

## ‚úÖ Verifica√ß√£o

Para verificar se os arquivos est√£o corretos:

```bash
# Listar arquivos
ls -lh artifacts/

# Dever√° mostrar:
# amzn_lstm_model.keras (tamanho varia, tipicamente alguns MB)
# scaler.save (tipicamente alguns KB)
```

## üîç Valida√ß√£o em Python

```python
import tensorflow as tf
import joblib

# Carregar modelo
model = tf.keras.models.load_model('artifacts/amzn_lstm_model.keras')
print(f"Model input shape: {model.input_shape}")
print(f"Model output shape: {model.output_shape}")

# Carregar scaler
scaler = joblib.load('artifacts/scaler.save')
print(f"Scaler features: {scaler.n_features_in_}")

# Valida√ß√µes esperadas:
# - Input shape: (None, 60, 5) - 60 timesteps, 5 features
# - Output shape: (None, 1) - 1 valor de predi√ß√£o
# - Scaler features: 5 (open, high, low, close, volume)
```

## ‚ö†Ô∏è Importante para Deploy

- **Tamanho:** Certifique-se de que o modelo n√£o √© muito grande
  - Vercel Hobby: Limite de 50MB para todo o deployment
  - Vercel Pro: Limite de 100MB
  
- **Formato:** Use `.keras` (n√£o `.h5`) para melhor compatibilidade

- **Versionamento Git:**
  - ‚ö†Ô∏è N√£o commite modelos muito grandes no Git
  - Considere usar Git LFS para arquivos grandes
  - Ou armazene em cloud storage e baixe durante CI/CD

## üì¶ Alternativas de Storage

Se o modelo for muito grande para Git:

### Op√ß√£o 1: Git LFS
```bash
# Instalar Git LFS
git lfs install

# Rastrear arquivos grandes
git lfs track "artifacts/*.keras"
git lfs track "artifacts/*.save"

# Commit
git add .gitattributes
git commit -m "Configurar Git LFS"
```

### Op√ß√£o 2: Cloud Storage
- Google Cloud Storage
- AWS S3
- Azure Blob Storage

Baixe durante o build/startup da aplica√ß√£o.

### Op√ß√£o 3: Vercel Blob
Use Vercel Blob Storage para armazenar artefatos grandes.

## üîÑ Atualiza√ß√£o de Modelo

Para atualizar o modelo em produ√ß√£o:

1. Substitua os arquivos na pasta `artifacts/`
2. Commit e push para o reposit√≥rio
3. Vercel far√° deploy autom√°tico
4. Cold start carregar√° o novo modelo

## üÜò Troubleshooting

**Erro: "Modelo n√£o encontrado"**
- Verifique se os arquivos est√£o nesta pasta
- Verifique permiss√µes de leitura

**Erro: "Cannot load model"**
- Verifique compatibilidade de vers√£o do TensorFlow
- Modelo foi salvo com TensorFlow 2.15.0
- Tente recriar o modelo com a vers√£o correta

**Erro: "Scaler incompat√≠vel"**
- Verifique se o scaler foi treinado com 5 features
- Ordem das features deve ser: open, high, low, close, volume

