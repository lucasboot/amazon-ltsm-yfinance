# Amazon LSTM Stock Price Prediction API

API RESTful construÃ­da com FastAPI para servir prediÃ§Ãµes de preÃ§os de aÃ§Ãµes da Amazon usando um modelo LSTM treinado com TensorFlow.

## ğŸš€ Features

- âœ… **Interface web moderna** com identidade visual Amazon
- âœ… **PrediÃ§Ã£o de preÃ§os** com modelo LSTM
- âœ… **Deploy serverless** na Vercel
- âœ… **Upload de CSV** ou entrada manual via JSON
- âœ… **Monitoramento integrado** com Vercel Observability
- âœ… **ValidaÃ§Ã£o robusta** de entrada com Pydantic
- âœ… **Health checks** e mÃ©tricas
- âœ… **CI/CD automÃ¡tico** via GitHub

## ğŸ“‹ Requisitos

- Python 3.9+
- Modelo LSTM treinado (`amzn_lstm_model.keras`)
- Scaler treinado (`scaler.save`)
- Conta na Vercel (gratuita)
- RepositÃ³rio no GitHub

## ğŸ—ï¸ Arquitetura

```
amazon-ltsm-yfinance/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ index.py              # Entrypoint FastAPI (serverless)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference.py          # Pipeline de inferÃªncia
â”‚   â”œâ”€â”€ model_loader.py       # Singleton para modelo/scaler
â”‚   â”œâ”€â”€ schemas.py            # Pydantic schemas
â”‚   â”œâ”€â”€ settings.py           # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ monitoring.py         # Logs e mÃ©tricas
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ amzn_lstm_model.keras # Modelo treinado
â”‚   â””â”€â”€ scaler.save           # Scaler joblib
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py           # Testes automatizados
â”‚   â””â”€â”€ test_payload.json     # Payload de exemplo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ vercel.json
â””â”€â”€ README.md
```

## ğŸ”§ Setup Local

### 1. Clone o repositÃ³rio

```bash
git clone <seu-repo>
cd amazon-ltsm-yfinance
```

### 2. Crie um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Coloque os artefatos do modelo

Certifique-se de ter os arquivos na pasta `artifacts/`:
- `amzn_lstm_model.keras` - Modelo LSTM treinado
- `scaler.save` - Scaler para normalizaÃ§Ã£o

### 5. Execute localmente

```bash
uvicorn api.index:app --reload
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`

## ğŸŒ Interface Web

Acesse `http://localhost:8000` no navegador para usar a **interface web interativa**!

**Features:**
- ğŸ“¤ Upload de arquivo CSV (drag & drop)
- âŒ¨ï¸ Entrada manual de dados (JSON)
- ğŸ¨ Design com identidade visual Amazon
- ğŸ“± Totalmente responsivo
- âœ… ValidaÃ§Ãµes automÃ¡ticas em tempo real


## ğŸ“¡ Endpoints

### `GET /`
**Interface Web HTML** - Acesse no navegador para usar a interface grÃ¡fica

### `GET /api`
InformaÃ§Ãµes bÃ¡sicas da API (JSON)

**Resposta:**
```json
{
  "name": "Amazon LSTM Stock Price Prediction API",
  "version": "1.0",
  "status": "online",
  "endpoints": {...}
}
```

---

### `POST /predict`
Prediz o prÃ³ximo preÃ§o de fechamento

**Entrada:** JSON com 60+ candles histÃ³ricos (OHLCV)

```json
{
  "data": [
    {
      "open": 150.2,
      "high": 152.1,
      "low": 149.8,
      "close": 151.5,
      "volume": 1000000
    },
    // ... mais 59 registros
  ]
}
```

**SaÃ­da:**
```json
{
  "prediction": 152.3,
  "timestamp": "2026-01-07T10:30:00Z",
  "model_version": "1.0"
}
```

**Exemplo com curl:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @tests/test_payload.json
```

---

### `GET /health`
Verifica status da API

**Resposta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "scaler_loaded": true,
  "timestamp": "2026-01-07T10:30:00Z"
}
```

---

### `GET /model/info`
InformaÃ§Ãµes do modelo

**Resposta:**
```json
{
  "model_version": "1.0",
  "lookback": 60,
  "features": ["open", "high", "low", "close", "volume"],
  "target": "close"
}
```

---

### `GET /metrics`
MÃ©tricas da aplicaÃ§Ã£o

**Resposta:**
```json
{
  "metrics": {
    "total_requests": 42,
    "total_predictions": 38,
    "total_errors": 2,
    "total_cold_starts": 1
  },
  "model_info": {...},
  "settings": {...}
}
```

## ğŸ§ª Testes

### Executar todos os testes

```bash
pytest tests/test_api.py -v
```

### Testar endpoint especÃ­fico

```bash
# Health check
curl http://localhost:8000/health

# PrediÃ§Ã£o com payload de exemplo
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @tests/test_payload.json
```

## ğŸš¢ Deploy na Vercel

### OpÃ§Ã£o 1: Via Dashboard (Recomendado)

1. **Crie conta na Vercel** (se ainda nÃ£o tiver)
   - Acesse: https://vercel.com/signup
   - FaÃ§a login com GitHub

2. **Importe o repositÃ³rio**
   - No dashboard, clique em "Add New Project"
   - Selecione seu repositÃ³rio do GitHub
   - Vercel detectarÃ¡ automaticamente o `vercel.json`

3. **Configure variÃ¡veis de ambiente** (opcional)
   - `LOG_LEVEL=INFO`
   - `MODEL_VERSION=1.0`

4. **Deploy automÃ¡tico**
   - Cada push na branch `main` â†’ deploy em produÃ§Ã£o
   - Pull requests â†’ preview deployments automÃ¡ticos

### OpÃ§Ã£o 2: Via CLI

```bash
# Instalar Vercel CLI
npm i -g vercel

# Login
vercel login

# Deploy
vercel --prod
```

## âš™ï¸ ConfiguraÃ§Ã£o do Vercel

O arquivo `vercel.json` jÃ¡ estÃ¡ configurado com:

- **Runtime:** Python 3.9+
- **Timeout:** 60s (ajustÃ¡vel)
- **MemÃ³ria:** 3008MB (mÃ¡ximo)
- **VariÃ¡veis de ambiente** prÃ©-configuradas

### âš ï¸ Limites Importantes

| Recurso | Hobby Plan | Pro Plan |
|---------|------------|----------|
| Tamanho do deploy | 50MB | 100MB |
| Timeout | 10s | 60s |
| MemÃ³ria | 1024MB | 3008MB |

**Nota:** Se o deploy exceder 50MB (por causa do TensorFlow), considere:
- Usar `tensorflow-cpu` em vez de `tensorflow` no `requirements.txt`
- Upgrade para plano Pro
- Considerar ONNX Runtime como alternativa

## ğŸ“Š Monitoramento

### Vercel Observability

Acesse o dashboard da Vercel para visualizar:
- **LatÃªncia** das requisiÃ§Ãµes
- **Erros** e stack traces
- **Uso de memÃ³ria** e CPU
- **Cold starts**
- **Logs estruturados**

### Logs Estruturados

Todos os logs sÃ£o em formato JSON para melhor anÃ¡lise:

```json
{
  "timestamp": "2026-01-07T10:30:00Z",
  "level": "INFO",
  "message": "OperaÃ§Ã£o concluÃ­da: full_inference_pipeline",
  "operation": "full_inference_pipeline",
  "duration_seconds": 0.234,
  "success": true
}
```


## ğŸ“ Notas TÃ©cnicas

### Modelo LSTM

- **Lookback:** 60 dias histÃ³ricos
- **Features:** Open, High, Low, Close, Volume
- **Target:** PreÃ§o de fechamento (Close) do prÃ³ximo dia
- **NormalizaÃ§Ã£o:** MinMaxScaler ou StandardScaler

### Pipeline de InferÃªncia

1. ValidaÃ§Ã£o dos dados (â‰¥60 registros, features vÃ¡lidas)
2. ExtraÃ§Ã£o das features (OHLCV)
3. SeleÃ§Ã£o dos Ãºltimos 60 registros
4. NormalizaÃ§Ã£o com scaler
5. Reshape para formato LSTM: `(1, 60, 5)`
6. PrediÃ§Ã£o com modelo
7. DesnormalizaÃ§Ã£o do resultado

## ğŸ“œ LicenÃ§a

Este projeto Ã© parte de um trabalho acadÃªmico da PÃ³s-Tech da FIAP.

---

**Status do Deploy:** [![Deploy](https://vercel.com/button)](https://vercel.com/import/project?template=https://github.com/seu-usuario/amazon-ltsm-yfinance)
